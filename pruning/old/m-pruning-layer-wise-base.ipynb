{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from transformers import RobertaModel, DistilBertModel, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU is available\n",
    "print(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_type, model_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    if model_path and os.path.exists(model_path):\n",
    "        # Try loading as a generic PyTorch model\n",
    "        try:\n",
    "            model = torch.load(model_path, map_location=device)\n",
    "        except Exception as e:\n",
    "            raise IOError(f\"Error loading model from {model_path}: {e}\")\n",
    "    elif model_type == 'distilroberta-base':\n",
    "        model = DistilBertModel.from_pretrained('distilroberta-base')\n",
    "    elif model_type == 'roberta-base':\n",
    "        model = RobertaModel.from_pretrained('roberta-base')\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type or path\")\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "def check_sparsity(model):\n",
    "    total_params = 0\n",
    "    nonzero_params = 0\n",
    "    layer_sparsity = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:  # exclude non-trainable parameters\n",
    "            continue\n",
    "        layer_size = param.numel()\n",
    "        layer_nonzero = torch.count_nonzero(param)\n",
    "        layer_sparsity[name] = 1 - layer_nonzero.item() / layer_size\n",
    "        total_params += layer_size\n",
    "        nonzero_params += layer_nonzero.item()\n",
    "    overall_sparsity = 1 - nonzero_params / total_params\n",
    "    print(f\"Overall Sparsity: {overall_sparsity:.4%}\")\n",
    "    layer_sparsity_df = pd.DataFrame(layer_sparsity.items(), columns=['Layer Name', 'Sparsity'])\n",
    "    # layer_sparsity_df.sort_values(by='Sparsity', ascending=False, inplace=True)\n",
    "    display(layer_sparsity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer-wise Pruning: Approach 1\n",
    "\n",
    "This approach calculates a threshold for each layer individually. It views the weights of a single layer as a flattened tensor, splits them into batches, and computes the quantile for each batch based on the pruning rate. The mean of these batched quantiles is used as the threshold for pruning the layer. This method applies the computed threshold to the layer's parameters, pruning weights below the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach1_threshold(param, pruning_rate, batch_size, device):\n",
    "    weights = param.view(-1)\n",
    "    batched_quantiles = [torch.quantile(batch.abs(), pruning_rate) for batch in weights.split(batch_size)]\n",
    "    return torch.tensor(batched_quantiles).mean().to(device)\n",
    "\n",
    "def mpruner_approach1(model, pruning_rate, batch_size, device):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.dim() > 1:\n",
    "            layer_threshold = approach1_threshold(param, pruning_rate, batch_size, device)\n",
    "            # print(f\"Layer: {name}, Threshold: {layer_threshold}\")\n",
    "            mask = param.abs() > layer_threshold\n",
    "            param.data.mul_(mask.to(torch.float32))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer-wise Pruning: Approach 2\n",
    "\n",
    "This method groups parameters by layer names and concatenates all the parameters of a layer before computing the threshold. It calculates a single threshold for each layer by considering all its parameters together, and then applies this threshold across all parameters of that layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach2_threshold(layer_params, pruning_rate, batch_size, device):\n",
    "    all_weights = [param.view(-1) for param in layer_params]\n",
    "    all_weights = torch.cat(all_weights).to(device)\n",
    "    batched_quantiles = [torch.quantile(batch.abs(), pruning_rate) for batch in all_weights.split(batch_size)]\n",
    "    return torch.tensor(batched_quantiles).mean().to(device)\n",
    "\n",
    "def mpruner_approach2(model, pruning_rate, batch_size, device):\n",
    "    layer_params = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.dim() > 1:\n",
    "            # Assuming layer name is the first part of the parameter name\n",
    "            layer_name = name.split('.')[0]\n",
    "            if layer_name not in layer_params:\n",
    "                layer_params[layer_name] = []\n",
    "            layer_params[layer_name].append(param)\n",
    "    for layer_name, params in layer_params.items():\n",
    "        layer_threshold = approach2_threshold(params, pruning_rate, batch_size, device)\n",
    "        # print(f\"Layer: {layer_name}, Threshold: {layer_threshold}\")\n",
    "        for param in params:\n",
    "            mask = param.abs() > layer_threshold\n",
    "            param.data.mul_(mask.to(torch.float32))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer-wise Pruning: Approach 3\n",
    "\n",
    "Approach 3 categorizes layers into types (e.g., embedding, attention, etc.) and computes a threshold for each category. It aggregates all weights of a given type across the model, computes the batched quantiles, and uses the maximum mean quantile as the threshold for that category. This method prunes parameters based on their layer type classification. This is a rather crude way of doing things, as categories could be ill-defined atm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach3_categorize(name):\n",
    "    if 'embeddings' in name:\n",
    "        return 'Embedding Layers'\n",
    "    elif 'attention.self.query' in name or 'attention.self.key' in name or 'attention.self.value' in name:\n",
    "        return 'Attention Layers'\n",
    "    elif 'attention.output' in name:\n",
    "        return 'Attention Output Layers'\n",
    "    elif 'intermediate' in name:\n",
    "        return 'Intermediate Layers'\n",
    "    elif 'output' in name:\n",
    "        return 'Encoder Output Layers'\n",
    "    elif 'pooler' in name:\n",
    "        return 'Pooling Layer'\n",
    "    elif 'LayerNorm' in name:\n",
    "        return 'Layer Normalizations'\n",
    "    elif 'dropout' in name:\n",
    "        return 'Dropout Layers'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "def approach3_threshold(model, pruning_rate, batch_size, device):\n",
    "    thresholds = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.dim() > 1:\n",
    "            layer_type = approach3_categorize(name)\n",
    "            all_weights = param.view(-1).abs().to(device)\n",
    "            batched_quantiles = [torch.quantile(batch, pruning_rate) for batch in all_weights.split(batch_size)]\n",
    "            layer_threshold = torch.tensor(batched_quantiles).mean().item()\n",
    "            if layer_type not in thresholds or thresholds[layer_type] < layer_threshold:\n",
    "                thresholds[layer_type] = layer_threshold\n",
    "    return thresholds\n",
    "\n",
    "def mpruner_approach3(model, pruning_rate, batch_size, device):\n",
    "    thresholds = approach3_threshold(model, pruning_rate, batch_size, device)\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.dim() > 1:\n",
    "            layer_type = approach3_categorize(name)\n",
    "            threshold = thresholds.get(layer_type, 0)\n",
    "            mask = param.abs() > threshold\n",
    "            param.data.mul_(mask.to(torch.float32))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.roberta.modeling_roberta.RobertaModel'>\n"
     ]
    }
   ],
   "source": [
    "model_type = 'roberta-base'     # Can be 'roberta-base', 'distilroberta-base', or a custom model path\n",
    "model_path = None               # Set this to None if you want to use pre-trained models\n",
    "\n",
    "# Loading model\n",
    "model = load_model(model_type, model_path)\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Sparsity: 0.0019%\n"
     ]
    }
   ],
   "source": [
    "# Checking sparsity before pruning\n",
    "layer_sparsity = check_sparsity(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning model\n",
    "pruning_rate = 0.2              # Between 0 and 1\n",
    "batch_size = 5000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_1 = mpruner_approach1(model, pruning_rate, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Sparsity: 20.4159%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embeddings.word_embeddings.weight</td>\n",
       "      <td>0.202470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>embeddings.position_embeddings.weight</td>\n",
       "      <td>0.200569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embeddings.token_type_embeddings.weight</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embeddings.LayerNorm.weight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embeddings.LayerNorm.bias</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>encoder.layer.11.output.dense.bias</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>encoder.layer.11.output.LayerNorm.weight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>encoder.layer.11.output.LayerNorm.bias</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>pooler.dense.weight</td>\n",
       "      <td>0.200075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>pooler.dense.bias</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Layer Name  Sparsity\n",
       "0           embeddings.word_embeddings.weight  0.202470\n",
       "1       embeddings.position_embeddings.weight  0.200569\n",
       "2     embeddings.token_type_embeddings.weight  1.000000\n",
       "3                 embeddings.LayerNorm.weight  0.000000\n",
       "4                   embeddings.LayerNorm.bias  0.000000\n",
       "..                                        ...       ...\n",
       "194        encoder.layer.11.output.dense.bias  0.000000\n",
       "195  encoder.layer.11.output.LayerNorm.weight  0.000000\n",
       "196    encoder.layer.11.output.LayerNorm.bias  0.000000\n",
       "197                       pooler.dense.weight  0.200075\n",
       "198                         pooler.dense.bias  1.000000\n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking sparsity after pruning\n",
    "check_sparsity(pruned_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: embeddings, Threshold: 0.0174578744918108\n",
      "Layer: encoder, Threshold: 0.0063947513699531555\n",
      "Layer: pooler, Threshold: 0.0022366500925272703\n"
     ]
    }
   ],
   "source": [
    "pruned_model_2 = mpruner_approach2(model, pruning_rate, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Sparsity: 20.4493%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embeddings.word_embeddings.weight</td>\n",
       "      <td>0.202470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>embeddings.position_embeddings.weight</td>\n",
       "      <td>0.306283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embeddings.token_type_embeddings.weight</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embeddings.LayerNorm.weight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embeddings.LayerNorm.bias</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>encoder.layer.11.output.dense.bias</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>encoder.layer.11.output.LayerNorm.weight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>encoder.layer.11.output.LayerNorm.bias</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>pooler.dense.weight</td>\n",
       "      <td>0.200075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>pooler.dense.bias</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Layer Name  Sparsity\n",
       "0           embeddings.word_embeddings.weight  0.202470\n",
       "1       embeddings.position_embeddings.weight  0.306283\n",
       "2     embeddings.token_type_embeddings.weight  1.000000\n",
       "3                 embeddings.LayerNorm.weight  0.000000\n",
       "4                   embeddings.LayerNorm.bias  0.000000\n",
       "..                                        ...       ...\n",
       "194        encoder.layer.11.output.dense.bias  0.000000\n",
       "195  encoder.layer.11.output.LayerNorm.weight  0.000000\n",
       "196    encoder.layer.11.output.LayerNorm.bias  0.000000\n",
       "197                       pooler.dense.weight  0.200075\n",
       "198                         pooler.dense.bias  1.000000\n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking sparsity after pruning\n",
    "check_sparsity(pruned_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_3 = mpruner_approach3(model, pruning_rate, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Sparsity: 20.8639%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embeddings.word_embeddings.weight</td>\n",
       "      <td>0.202470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>embeddings.position_embeddings.weight</td>\n",
       "      <td>0.308107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embeddings.token_type_embeddings.weight</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embeddings.LayerNorm.weight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embeddings.LayerNorm.bias</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>encoder.layer.11.output.dense.bias</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>encoder.layer.11.output.LayerNorm.weight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>encoder.layer.11.output.LayerNorm.bias</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>pooler.dense.weight</td>\n",
       "      <td>0.200075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>pooler.dense.bias</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Layer Name  Sparsity\n",
       "0           embeddings.word_embeddings.weight  0.202470\n",
       "1       embeddings.position_embeddings.weight  0.308107\n",
       "2     embeddings.token_type_embeddings.weight  1.000000\n",
       "3                 embeddings.LayerNorm.weight  0.000000\n",
       "4                   embeddings.LayerNorm.bias  0.000000\n",
       "..                                        ...       ...\n",
       "194        encoder.layer.11.output.dense.bias  0.000000\n",
       "195  encoder.layer.11.output.LayerNorm.weight  0.000000\n",
       "196    encoder.layer.11.output.LayerNorm.bias  0.000000\n",
       "197                       pooler.dense.weight  0.200075\n",
       "198                         pooler.dense.bias  1.000000\n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking sparsity after pruning\n",
    "check_sparsity(pruned_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to roberta-base-mpruned-layerwise-base-0.20.pt\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "filename = f\"{model_type}-mpruned-layerwise-base-{pruning_rate:.2f}.pt\"\n",
    "print(f\"Saving model to {filename}\")\n",
    "torch.save(pruned_model_1, filename)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teamproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
